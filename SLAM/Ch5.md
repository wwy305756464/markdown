# 相机与图像

## 相机模型

### 针孔相机模型

针孔相机模型描述了一束光通过针孔之后，在针孔背面投影成像

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200711184452957.png" alt="image-20200711184452957" style="zoom: 50%;" />

#### 这里有如下几个坐标系/平面：

* 世界坐标系：P点在现实世界中的坐标为 $P:[X,Y,Z]$

* 相机坐标系：$O-x-y-z$ 为相机坐标系，一般 z 指向相机前方，x 轴向右，y 轴向下。O为光心，即针孔

* 物理成像平面：P 点通过针孔后在物理成像平面上为 P', 它的坐标为 $P':[X',Y',Z']$

* 像素平面：将其他平面以米为单位的坐标转换成二维像素坐标：$P':[u,v]^T$

  * 像素坐标系：

    * 一般原点 $o'$ 位于图像的左上角，$u$ 轴向右与 $x$ 轴平行，$v$ 轴向下与 $y$ 轴平行
  * 这里引入了一个缩放和原点的平移，在物理成像平面和像素平面之间
    * 像素坐标在 $u$ 轴上缩放了 $\alpha$ 倍，在 $v$ 轴上缩放了 $\beta$ 倍，原点平移了 $[c_x, c_y]^T$
  
* 归一化坐标：在相机前方 z=1 的地方有一个平面，用来证明在单目相机中深度消失

  

#### 数学关系：

##### 世界坐标系与物理成像平面：(这里忽视倒立成像)，$f$ 为焦距（物理成像平面到小孔的距离）

$$
\frac{Z}{f}=\frac{X}{X'}=\frac{Y}{Y'},\space \space \space X'=f\frac{X}{Z},\space \space \space Y'=f\frac{Y}{Z}
$$
##### 物理成像平面与像素平面：

$$
\begin{cases}
u=\alpha X'+c_x=f_x\frac{X}{Z}+c_x\space \space \space \space ,  \space \space \space \space f_x=\alpha f\\
v=\beta Y'+c_y=f_y\frac{Y}{Z}+c_y\space \space \space \space ,  \space \space \space \space f_y=\beta f
\end{cases}
$$
​	写成矩阵形式：
$$
\begin{bmatrix} 
u \\ v \\ 1
\end {bmatrix} = \frac{1}{Z} \underbrace {\begin{bmatrix}
f_x && 0 && c_x \\ 0 && f_y && c_y \\ 0 && 0 && 1
\end{bmatrix}}_{K} \begin{bmatrix}
X \\ Y\\ Z
\end{bmatrix} = \frac{1}{Z}KP
$$

这里的 K 被称为相机的**内参数（Camera Intrinsic）**，一般为相机出厂内定的，即标定。

**外参（Camera Extrinsic）**：

​	这里P是相机坐标系下的坐标，但是实际上P的相机坐标应该是它的世界坐标（$P_W$）根据相机的当前位姿变换到相机坐标系下的结果。如果我们将位姿写成旋转矩阵加上平移向量的模式，那么：
$$
ZP_{uv}=Z\begin{bmatrix}u\\v\\1 \end{bmatrix} = K(RP_W+t)=KTP_W
$$
​	这里相机的位姿 R,t 就是相机的外参。外参会随着相机运动而改变，也是SLAM中需要估计的目标。

#### 为什么单目相机的深度在投影过程中会消失？

​	由上面的公式我们得知通过一个的点的世界坐标和平移的量，还有相机的内参，我们可以得到这个点在像素平面上的坐标。这里已经将3D转换为2D了，就相当于把最后一维进行了归一化处理，得到了P点在相机归一化平面上的投影：
$$
(RP_W+t)=\underbrace{[X,Y,Z]^T}_{相机坐标} \to \underbrace{[\frac{X}{Z},\frac{Y}{Z},1]^T}_{归一化坐标}
$$
​	我们可以简单将归一化坐标理解为相机前方 z=1 处的平面上有一个点，那么这个 z=1 的平面就被称为归一化平面。归一化坐标再左乘内参就得到了像素坐标，所以我们可以将像素坐标 [u,v] 看作对归一化平面上的点进行量化测量的结果。

​	因为这里我们发现，对于相机坐标同时乘上任意非零常数，归一化坐标都是一样的。所以点的深度在投影过程中丢失了，单目视觉中没法得到像素点的深度值。



### 畸变模型

#### 畸变（Distortion）

在相机前方添加透镜，一是透镜自身的形状对光线传播有影响，而是组装过程中，透镜和成像平面不完全平行，使光线穿过透镜投影到成像面时位置发生变化。比如针孔模型中一条直线投影到像素平面上还是一条直线，但透镜会使其变成曲线，且一般镜像对称。

##### 径向畸变：桶形畸变 vs. 枕形畸变

​	桶形畸变图像的放大率随着与光轴之间的距离增加而减小，枕形畸变相反。但是穿过图像中心和光轴有交点的直线在两种情况下均保持形状不变。

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200713162219100.png" alt="image-20200713162219100" style="zoom:50%;" />

##### 切向畸变

​	在相机组装过程中的误差使透镜和成像面不能严格平行叫做切向畸变

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200713162759032.png" alt="image-20200713162759032" style="zoom:43%;" />

​	假设一个点在归一化平面上，可以用$(x,y)$或者$(r,\theta)$表示。那么使 $r$ 发生变化的使径向畸变，使 $\theta$ 发生变化的是切向畸变。我们可以用多项式来表示这两种畸变：

##### 径向畸变的多项式表示

$$
x_{distorted}=x(1+k_1r^2+k_2r^4+k_2r^6) \\
y_{distorted}=y(1+k_1r^2+k_2r^4+k_2r^6)
$$

##### 切向畸变的多项式表示

$$
x_{distorted}=x+2p_1xy+p_2(r^2+2x^2) \\
y_{distorted}=y+2p_2xy+p_1(r^2+2y^2)
$$

如果我们将这两种畸变的情况相加，那么对于投影到归一化图像平面上的 $[x,y]$ 点，它在这个平面上的畸变量为：
$$
x_{distorted}=x(1+k_1r^2+k_2r^4+k_2r^6)+2p_1xy+p_2(r^2+2x^2) \\
y_{distorted}=y(1+k_1r^2+k_2r^4+k_2r^6)+2p_2xy+p_1(r^2+2y^2)
$$
那么如果将畸变后的点再通过内参数矩阵投影到像素平面，该点在图像上的正确位置为：
$$
\begin{cases}
u = f_xx_{distorted}+c_x \\
v=f_yy_{distorted}+c_y
\end{cases}
$$


### 单目相机的成像过程

1. 世界坐标系下有一个固定的点 P， 其世界坐标为 $P_W$
2. 由于相机在运动，它的运动由 R,t 或变换矩阵 $T\in SE(3)$ 描述。P 的相机坐标为 $P_C=RP_W+t$
3. 这时的 $P_C$ 的坐标为 $[X,Y,Z]$, 把它们投影到归一化平面 $Z=1$ 上，得到 P 的归一化坐标：$P_C=[\frac{X}{Z},\frac{Y}{Z},1]^T$
4. 如果有畸变，那么根据畸变参数计算 $P_C$ 发生畸变后的坐标
5. P 的归一化坐标经过内参后，可以对应到它的像素坐标：$P_{uv}=KP_C$



### 双目相机模型

​	我们已经知道单目相机无法确定某个像素点在这个空间内的具体位置（深度），只能知道它可以在这一条连线上的任意位置。所以我们需要使用双目相机来确定像素点的深度。

#### 双目相机的原理

​	双目相机的基本原理就是通过同步采集左右相机的图像，计算相机间视差，来估计每个像素的深度

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200713175802884.png" alt="image-20200713175802884" style="zoom:50%;" />

​	这里有 L,R 两个相机，$O_L,O_R$ 是这两个相机的光圈中心，f 为两个相机的焦距，$u_R,u_L$ 分别为某个点在两个成像平面上的坐标。这里我们默认两个相机是水平仿制的，所以两个光圈中心都在 x 轴上。（这也说明了这个点在两个相机下，只有 u 是不同的）两个光圈之间的距离 b 被称为双目相机的**基线**。

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200713182621858.png" alt="image-20200713182621858" style="zoom:26%;" />

​	通过上述模型的相似三角形关系，我们可以得到：
$$
\frac{z-f}{z}=\frac{b-u_L+u_R}{b} \to z=\frac{fb}{d};d=u_L-u_R
$$
​	这里的 d 就是两个图的横坐标之差，**视差**。视差与距离成反比：视差越大，距离越近。



### RGB-D相机模型

​	RGB-D相机也可以得到深度，但是它是主动测量每个像素的深度。RGB-D相机有两种类型，根据测量深度的原理。第一种是通过红外结构光（Structured Light）原理测量像素距离，第二种是通过飞行时间（Time-of-Flight, ToF）原理来测量像素距离。

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200713214527553.png" alt="image-20200713214527553" style="zoom:50%;" />

​	RGB-D相机要向探测目标发射一束红外光。如果是红外结构光原理，那么相机会根据返回的结构光图案来计算物体与自身之间的距离；如果是ToF原理，相机会向物体发送脉冲光，然后根据发送到返回之间光束的飞行时间来确定物体与自身的距离。与激光传感器不同的点在于，激光传感器是探测到一个点就返回一个点的信息，而ToF是将这个图像的像素深度一起获得。在探测到深度之后，RGB-D相机会按照生产时相机的摆放位置完成深度与色彩图像素之间的配对，输出一一对应的彩色图与深度图，然后生成点云（Point Cloud）。所以我们既可以在图像层对RGB-D数据进行处理，也可以在点云层进行处理。

​	RGB-D相机的优点在于能够实时地测量每个像素点的距离。缺点在于用红外光测量时只能子室内使用，因为室外会受到日光的影响。同时多个RGB-D相机一起使用时也会被互相影响。以及对于接收光照的物体的材质有一定的限制。



## 图像

图像在计算机中使用一个二维数组来表示的。

### 灰度图

* 在一张灰度图中，每个像素位置 $(x,y)$ 对应了一个灰度值 $I$。通常，$x,y$ 为从0开始的整数，灰度图中用 $0~255$ 来表示图像的灰度读数（unsigned char, 一个字节）。那么一个宽度为 640 像素，高 480 像素的灰度图可以表示为：

```c++
unsigned char image[480][640];
unsigned char image[# of rows][num of cols];
```

* 这里数组的行数对应图像的高度，列数对应图像的宽度。

* 同时，x 轴对应图像的宽度/列数，y 轴对应图像的高度/行数

```c++
unsigned char pixel = image[y][x]; // 访问一个位于（x,y）处的元素
```

* 8位整数可以用来记录一个像素的灰度，但是记录深度的信息需要用到16位整数（unsigned short）

### 彩色图

* 彩色图像中，每个像素由R,G,B三个通道（channel）组成，每个通道占据8位整数，一个像素占据24位
* OpenCV库中是按照 B,G,R 的顺序存储的
* 如果加上像素的透明度，就是有 R, G, B, A 四个通道

### 图像坐标

<img src="C:\Users\Wenyue Wang\AppData\Roaming\Typora\typora-user-images\image-20200719165917001.png" alt="image-20200719165917001" style="zoom: 50%;" />



## openCV 中的插值

### 最邻插值法

<img src="https://img2018.cnblogs.com/blog/1344541/201903/1344541-20190320150115061-1373571893.png" alt="img" style="zoom:67%;" />

* 设 $(i+u, j+v)$ 为待求象素的坐标, 则待求象素的灰度值为 $f(i+u,j+v)$，这里 i, j 为正整数，u, v为大于零小于1的小数

* 如果 $(i+u, j+v)$ 落在A区，即u<0.5, v<0.5，则将左上角象素的灰度值赋给待求象素，同理，落在B区则赋予右上角的象素灰度值，落在C区则赋予左下角象素的灰度值，落在D区则赋予右下角象素的灰度值。

* 最邻近元法计算量较小，但可能会造成插值生成的图像灰度上的不连续，在灰度变化的地方可能出现明显的锯齿状。



### 双线性插值

线性插值：已知数据 $(x_0,y_0)$ 和 $(x_1, y_1)$，计算 $[x_0,x_1]$ 区间内某一位置 x 在直线上的 y 值：
$$
\frac{y-y_0}{x-x_0}=\frac{y_1-y_0}{x_1-x_0}\space \to \space y=\frac{x_1-x}{x_1-x_0}y_0+\frac{x-x_0}{x_1-x_0}y_1
$$
双线性插值就是在两个方向上进行线性插值：

<img src="https://img2018.cnblogs.com/blog/1344541/201903/1344541-20190320150349425-1843375380.png" alt="img" style="zoom: 33%;" />

假如我们想得到未知函数 $f$ 在点 $P=(x,y)$ 的值，我们已经知道在周围四个点 $Q_{11},Q_{12},Q_{21},Q_{22}$的值，那么我们可以通过两个线性插值得到点 $R_1,R_2$ 的值。根据 $R_1, R_2$ 再进行一次线性插值得到 $P$ 点的值。
$$
f(x,y)=\frac{f(Q_{11})}{(x_2-x_1)(y_2-y_1)}(x_2-x)(y_2-y)+\frac{f(Q_{21})}{(x_2-x_1)(y_2-y_1)}(x-x_1)(y_2-y) \\
+\frac{f(Q_{12})}{(x_2-x_1)(y_2-y_1)}(x_2-x)(y-y_1)+\frac{f(Q_{22})}{(x_2-x_1)(y_2-y_1)}(x-x_1)(y-y_1)
$$
如果我们将$Q_{11},Q_{12},Q_{21},Q_{22}$的坐标简化为$(0,0),(0,1),(1,0),(1,1)$, 插值公式变为：
$$
f(x,y)=f(0,0)(1-x)(1-y)+f(1,0)x(1-y)+f(0,1)(1-x)y+f(1,1)xy \\
f(x,y)=\begin{bmatrix}1-x && x
\end{bmatrix} \begin{bmatrix}
f(0,0) && f(0,1) \\ f(1,0) && f(1,1)
\end{bmatrix} \begin{bmatrix} 1-y \\ y\end{bmatrix}
$$
双线性内插法的计算比最邻近点法复杂，计算量较大但没有灰度不连续的缺点，结果基本令人满意，它具有低通滤波性质，使高频分量受损，图像轮廓可能会有一点模糊

 